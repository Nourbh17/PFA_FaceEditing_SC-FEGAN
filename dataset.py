# -*- coding: utf-8 -*-
"""Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eR7eJFq2wpcd0ITXuXesL3N5pnKo2j-p
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np

"""import zipfile
import os
# Path to the zip file
zip_file_path = '/content/drive/MyDrive/CelebAMask-HQ.zip'

# Directory where you want to extract the contents
extracted_dir = '/content/drive/MyDrive/celebahq'

# Create the target directory if it doesn't exist
os.makedirs(extracted_dir, exist_ok=True)

# Extract the contents of the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_dir)

# List the contents of the extracted directory
extracted_files = os.listdir(extracted_dir)
print(f"Contents of {extracted_dir}: {extracted_files}")
"""

data_dir= '/content/drive/MyDrive/PFA/test/input'
data = tf.keras.utils.image_dataset_from_directory(data_dir,labels=None,label_mode=None,shuffle=True,image_size=(512,512),batch_size=None)

for batch in data.take(1):
    print(batch.shape)

data

import matplotlib.pyplot as plt

for batch in data.take(1):
    first_image = batch.numpy()
    plt.imshow(first_image.astype("uint8"))
    plt.axis("off")
    plt.show()
    break

import numpy as np
import cv2 as cv
from face_toolbox_keras_master.models.parser.BiSeNet.bisenet import BiSeNet_keras
FILE_PATH = "D://Deep_Learning_projects/new_projects/computer_vision/project_3/face_toolbox_keras_master/models/parser"


class FaceParser():
    def __init__(self, path_bisenet_weights=FILE_PATH + "/BiSeNet/BiSeNet_keras.h5", detector=None):
        self.parser_net = None
        self.detector = detector
        self.build_parser_net(path_bisenet_weights)

    def build_parser_net(self, path):
        parser_net = BiSeNet_keras()
        parser_net.load_weights(path)
        self.parser_net = parser_net

    def set_detector(self, detector):
        self.detector = detector

    def remove_detector(self):
        self.detector = None

    def parse_face(self, im, bounding_box=None, with_detection=False):
        orig_h, orig_w = im.shape[:2]

        # Detect/Crop face RoI
        if bounding_box == None:
            if with_detection:
                try:
                    self.detector.fd
                except:
                    raise NameError("Error occurs during face detection: \
                    detector not found in FaceParser.")
                bboxes = self.detector.fd.detect_face(im)
                faces = []
                for bbox in bboxes:
                    y0, x0, y1, x1, _ = bbox
                    x0, y0 = np.maximum(x0, 0), np.maximum(y0, 0)
                    x1, y1 = np.minimum(x1, orig_h), np.minimum(y1, orig_w)
                    x0, y0, x1, y1 = map(np.int32, [x0, y0, x1, y1])
                    faces.append(im[x0:x1, y0:y1, :])
            else:
                faces = [im]
        else:
            x0, y0, x1, y1 = bounding_box
            x0, y0 = np.maximum(x0, 0), np.maximum(y0, 0)
            x1, y1 = np.minimum(x1, orig_h), np.minimum(y1, orig_w)
            x0, y0, x1, y1 = map(np.int32, [x0, y0, x1, y1])
            faces = [im[x0:x1, y0:y1, :]]

        maps = []
        for face in faces:
            # Preprocess input face for parser networks
            orig_h, orig_w = face.shape[:2]
            inp = cv.resize(face, (512, 512))
            inp = self.normalize_input(inp)
            inp = inp[None, ...]

            # Parser networks forward pass
            # Do NOT use bilinear interp. which adds artifacts to the parsing map
            out = self.parser_net.predict([inp])[0]
            parsing_map = out.argmax(axis=-1)
            parsing_map = cv.resize(
                parsing_map.astype(np.uint8),
                (orig_w, orig_h),
                interpolation=cv.INTER_NEAREST)
            maps.append(parsing_map)
        return maps

    @staticmethod
    def normalize_input(x, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):
        # x should be RGB with range [0, 255]
        return ((x / 255) - mean) / std

!pip install mediapipe

# train_split = 0.03334

# # Create training dataset
# train_ds = tf.keras.utils.image_dataset_from_directory(
#     data_dir,
#     labels=None,label_mode=None,
#     validation_split=train_split,
#     subset="training",
#     seed=123,  # Set random seed for reproducibility
#     image_size=(512, 512),
#     batch_size=32  # Adjust batch size as needed
# )

# # Create test dataset
# test_ds = tf.keras.utils.image_dataset_from_directory(
#     data_dir,
#     labels=None,label_mode=None,
#     validation_split=train_split,
#     subset="validation",  # Use "validation" to get the remaining split
#     seed=123,  # Keep the same seed for consistency
#     image_size=(512, 512),
#     batch_size=32
# )

# # Print information about the datasets
# print("Training dataset size:", train_ds.cardinality())
# print("Test dataset size:", test_ds.cardinality().numpy())

test_dataset = data.take(1000)
train_dataset = data.skip(1000)

len(test_dataset)

def free_form_mask(IntputImage,inputSize, maxDraw=100, maxLine=100, maxAngle=120, maxLength=100,max_width=50):
  mask=np.zeros((inputSize,inputSize),np.float32)
  #HairMask=hairMask(IntputImage)
  numLine=np.random.randint(maxDraw)
  for i in range(numLine):
      startX = np.random.randint(inputSize)
      startY = np.random.randint(inputSize)

      mask=subFFmask(inputSize, maxAngle, maxLength,maxLine,max_width,startX,startY,mask)
      e1,e2= give_eye_position(IntputImage)
      mask=subFFmask(inputSize, maxAngle, maxLength,max_width,e1[0],e1[1],mask)
      mask=subFFmask(inputSize, maxAngle, maxLength,max_width,e2[0],e2[1],mask)



  #mask = mask +HairMask
  return mask.reshape((1, ) + mask.shape).astype(np.float32)

def subFFmask(inputSize, maxAngle, maxLength,maxLine,max_width,startX,startY,mask):
  startAngle = np.random.randint(360)
  numV =np.random.randint(maxLine)
  for j in range(numV):
         angleP = np.random.randint(-maxAngle,maxAngle)
         if (j % 2)==0:
           angle = startAngle+angleP
         else:
           angle = startAngle+angleP+180

         length = np.random.randint(maxLength)
         brush_w = 5 + np.random.randint(max_width)
         end_x = (startX + length * np.sin(angle)).astype(np.int32)
         end_y = (startY + length * np.cos(angle)).astype(np.int32)
         cv2.line(mask, (startX, startX), (end_y, end_x), 1.0, brush_w)
         startX, startY = end_x, end_y
  return mask.reshape((1, ) + mask.shape).astype(np.float32)

import mediapipe as mp
import cv2
def give_eye_position(img):

 # Load the MediaPipe FaceMesh solution
 mp_face_mesh = mp.solutions.face_mesh
 face_mesh = mp_face_mesh.FaceMesh()



 # Process the image with FaceMesh
 results = face_mesh.process((cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))

 # Extract the eye centers
 if results.multi_face_landmarks:
    for face_landmarks in results.multi_face_landmarks:
        # Define the landmark indices for the left and right eye
        left_eye_landmark_indices = [33, 133, 143, 153, 159, 145]
        right_eye_landmark_indices = [362, 263, 373, 380, 374, 386]

        # Initialize the eye center coordinates
        left_eye = [0, 0]
        right_eye = [0, 0]
        for i in range(2):
         e1=np.random.choice(left_eye_landmark_indices)
         e2=np.random.choice(right_eye_landmark_indices)
         landmark = face_landmarks.landmark[e1]
         x = int(landmark.x * img.shape[1])
         y = int(landmark.y * img.shape[0])
         left_eye[0] += x
         left_eye[1] += y
         landmark = face_landmarks.landmark[e2]
         xx = int(landmark.x * img.shape[1])
         yy = int(landmark.y * img.shape[0])
         right_eye[0] += x
         right_eye[1] += y



    # Calculate the average eye center coordinates
    left_eye[0] //= 2
    left_eye[1] //= 2
    right_eye[0] //= 2
    right_eye[1] //= 2
    return  (left_eye, right_eye)

import cv2
img=cv2.imread("/content/drive/MyDrive/celebahq/CelebAMask-HQ/CelebA-HQ-img/29999.jpg")

img.size

img.shape

first_image_uint8 = (first_image * 255).astype(np.uint8)

masked= free_form_mask(first_image_uint8, first_image_uint8.shape[0])
cv2.imshow(masked)

def hairMask(pic):
  parser = FaceParser()
  img = pic[..., ::-1]
  parsed = parser.parse_face(img, with_detection=False)
  component_mask = np.zeros(tuple(img.shape[:-1]))
  component_mask[parsed[0] == 17] = 1
  component_mask = np.reshape(component_mask, (img.shape[0], img.shape[1], 1))
  return component_mask.astype("float32")

def edges_detection(pic):
        (H, W) = pic.shape[:2]
        blob = cv.dnn.blobFromImage(pic, scalefactor=1.0, size=(W, H),
                                    swapRB=False, crop=False)
        net = cv.dnn.readNetFromCaffe("deploy.prototxt.txt", "hed_pretrained_bsds.caffemodel")
        net.setInput(blob)
        hed = net.forward()
        hed = cv.resize(hed[0, 0], (pic.shape[0], pic.shape[1]))
        hed = (255 * hed).astype("uint8")
        ret2, th2 = cv.threshold(hed, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        binary_mask = np.reshape(th2, (pic.shape[0], pic.shape[1], 1))
        return binary_mask.astype(np.uint8)